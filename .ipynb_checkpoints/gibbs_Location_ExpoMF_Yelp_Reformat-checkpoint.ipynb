{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Exposure MF with exposure covariantes (Location ExpoMF) to the Gowalla dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py2\\lib\\site-packages\\matplotlib\\__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import os\n",
    "# if you are using OPENBLAS, you might want to turn this option on. Otherwise, joblib might get stuck\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change this to suit your need before running\n",
    "FOLDER_NAME = 'gowalla_pro'\n",
    "COUNT_NAME = '/USERCOUNT_6000_MINSC_30'\n",
    "DATA_ROOT = '../' + FOLDER_NAME\n",
    "ID_DATA_ROOT = DATA_ROOT + COUNT_NAME\n",
    "num_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_uid = list()\n",
    "with open(os.path.join(ID_DATA_ROOT, 'unique_uid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "    \n",
    "unique_sid = list()\n",
    "with open(os.path.join(ID_DATA_ROOT, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298 3666\n"
     ]
    }
   ],
   "source": [
    "n_songs = len(unique_sid)\n",
    "n_users = len(unique_uid)\n",
    "print n_songs, n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(csv_file, shape=(n_users, n_songs)):\n",
    "    tp = pd.read_csv(csv_file)    \n",
    "    rows, cols = np.array(tp['uid'], dtype=np.int32), np.array(tp['sid'], dtype=np.int32)\n",
    "    count = tp['rating']\n",
    "    return scipy.sparse.csr_matrix((count,(rows, cols)), dtype=np.int16, shape=shape), rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, rows, cols = load_data(os.path.join(ID_DATA_ROOT, 'train.num.csv'))\n",
    "# binarize the data, setting all data equal 1\n",
    "train_data.data = np.ones_like(train_data.data)\n",
    "vad_data, rows_vad, cols_vad = load_data(os.path.join(ID_DATA_ROOT, 'vad.num.csv'))\n",
    "# binarize the data\n",
    "vad_data.data = np.ones_like(vad_data.data)\n",
    "test_data, rows_test, cols_test = load_data(os.path.join(ID_DATA_ROOT, 'test.num.csv'))\n",
    "# binarize the data\n",
    "test_data.data = np.ones_like(test_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feat_venue_locs.tsv` contains the location features (part of the [pre-processed data](http://dawenl.github.io/data/gowalla_pro.zip)), which are generated in the following way: \n",
    "- Run GMM (from [scikit.learn](http://scikit-learn.org/)) on all the venue locations.\n",
    "- For each venue, take the expected cluster assignment as location features `pi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtering out locations that should have been filtered out. see filter_triplets\n",
    "pi = np.loadtxt(os.path.join(DATA_ROOT, 'feat_venue_locs.tsv'), dtype='float32')\n",
    "mask = np.ones(pi.shape, dtype=bool)\n",
    "for i in range(0, pi.shape[0]):\n",
    "    if \"%d\" % pi[i, 0] not in unique_sid:\n",
    "        mask[i,:] = False\n",
    "pi = pi[mask,...]\n",
    "pi = pi.reshape(-1, num_features+1)\n",
    "\n",
    "\n",
    "# sanity check to make sure all the venues has its corresponding feature    \n",
    "for i, s in enumerate(unique_sid):\n",
    "    if s != \"%d\" % pi[i, 0]:\n",
    "        print i, s, pi[i, 0]\n",
    "        break\n",
    "# the first column of pi is sid\n",
    "# the first column is ID, don't need them\n",
    "pi = pi[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paral_gibbs3_expomf_cov\n",
    "import gibbs3_expomf_cov\n",
    "n_components = 100\n",
    "max_iter = 10\n",
    "n_jobs = 1\n",
    "lam = 1e-5\n",
    "# here we use the best performing init_mu from per-item \\mu_i experiment\n",
    "init_mu = 0.01\n",
    "max_epoch = 10\n",
    "\n",
    "save_dir=FOLDER_NAME + \"Paral_gibb3_ExpoMF_params_K%d_lam%1.0E_initmu%1.0E_maxepoch%d\" % (n_components, lam, init_mu, max_epoch)\n",
    "\n",
    "#coder = expomf_cov.ExpoMF(n_components=n_components, max_iter=max_iter, batch_size=1000, \n",
    "#                          batch_sgd=10, max_epoch=max_epoch, init_std=0.01,\n",
    "#                          n_jobs=n_jobs, random_state=98765, save_params=True, save_dir=save_dir, \n",
    "#                          early_stopping=True, verbose=True, \n",
    "#                          lam_y=1., lam_theta=lam, lam_beta=lam, lam_nu=lam, init_mu=init_mu, learning_rate=.5)\n",
    "import paral_gibbs3_expomf_cov\n",
    "coder = paral_gibbs3_expomf_cov.ExpoMF(n_components=n_components, max_iter=max_iter, batch_size=10000, \n",
    "                          batch_sgd=100, max_epoch=max_epoch, init_std=0.01,\n",
    "                          n_jobs=n_jobs, random_state=98765, save_params=True, save_dir=save_dir, \n",
    "                          early_stopping=True, verbose=True, \n",
    "                          lam_y=1., lam_theta=lam, lam_beta=lam, lam_nu=lam, init_mu=init_mu, learning_rate=.5, debugCov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to sample...\n",
      "Iteration: #0\n",
      "\tSampling exposure covariate: time=0.89\n",
      "\tSampling user factors...[  5.97761202e+04  -7.45393477e+02  -4.47580123e+02   3.40737546e+02\n",
      "  -1.96931337e+03  -2.47718843e+02   1.75716916e+03   8.64062965e+01\n",
      "   1.27354460e+03  -1.32524780e+03   2.37139746e+01   2.99693230e+02\n",
      "  -2.85824803e+02  -1.76770031e+03  -1.09582304e+03   6.38783022e+02\n",
      "  -1.75793419e+03   8.16401683e+02  -1.11564534e+03  -8.03272321e+02\n",
      "   6.60182578e+02  -3.47220740e+02  -4.93362470e+02   8.29269283e+02\n",
      "  -3.75647421e+02   6.67408769e+02  -2.16676307e+02  -6.63342916e+02\n",
      "  -2.99284454e+03  -1.37145284e+03  -4.66139258e+02   6.09092324e+02\n",
      "  -1.25195827e+03   6.75182537e+02  -5.89762551e+02  -1.68991979e+03\n",
      "  -1.86679869e+03  -5.84280741e+02  -1.67496018e+03   1.27593983e+03\n",
      "   4.49540070e+02  -5.90544561e+02   3.44470366e+02   1.88475552e+03\n",
      "  -4.12567105e+02   5.96403079e+02  -6.27619523e+02  -8.44495564e+02\n",
      "  -7.57943337e+02   1.28461216e+03  -4.80847726e+02  -1.57082575e+03\n",
      "  -8.17425789e+02   9.53823299e+01  -2.62673289e+02  -7.98582901e+02\n",
      "  -2.01967919e+02   8.23596881e+02   1.51968573e+02   1.25160909e+03\n",
      "  -2.98897004e+03  -1.36440556e+03   2.31363160e+03  -1.95556316e+01\n",
      "   1.84821848e+03   3.52639052e+01  -1.14126309e+03   1.43511013e+03\n",
      "   9.97643254e+02   1.32863266e+03   7.45596083e+02   8.51790571e+02\n",
      "  -3.61848310e+02   8.29095684e+02   2.32227625e+03   2.14158316e+03\n",
      "  -8.46257062e+02  -1.09335816e+03  -2.67236184e+03  -1.03478128e+03\n",
      "  -4.79610829e+02  -1.35684956e+03  -6.74360814e+02   2.22369996e+03\n",
      "   8.42325179e+02  -1.11008448e+03   2.01905515e+03   2.19404058e+03\n",
      "  -9.99776455e+02   1.40040741e+02  -2.34040722e+03  -4.12152316e+02\n",
      "  -8.31522127e+02  -8.13292021e+01  -1.74092139e+03   6.05872135e+02\n",
      "  -1.09236113e+03  -1.50217612e+03   1.84949763e+02  -1.18824233e+03]\n",
      "\tSampling user factors: time=27.99\n",
      "\tSampling item factors: time=52.45\n",
      "\tSampling location exposure covariates: time=0.66\n",
      "The MSE are:91.48 and 27.25\n",
      "Iteration: #1\n",
      "\tSampling exposure covariate: time=0.91\n",
      "\tSampling user factors...[  6.59057710e+04  -2.99418700e+02  -9.61147513e+02  -2.15636059e+03\n",
      "  -1.32519853e+03  -8.46559981e+02   4.49210846e+02  -1.43424927e+02\n",
      "  -1.29292703e+02  -6.77162184e+02   1.67564882e+03  -1.21911161e+03\n",
      "  -5.15845715e+01  -2.70596694e+03   7.26026894e+02  -4.34228281e+02\n",
      "   1.61804735e+02   7.37886706e+02  -1.37263802e+02   2.77218250e+03\n",
      "  -2.29107204e+02   3.62415963e+02   1.05451269e+03   2.36288721e+03\n",
      "  -3.96502891e+02   3.64289500e+02  -2.46645555e+03  -1.58181486e+03\n",
      "   1.98035401e+03  -1.85257000e+03   2.21247625e+03   2.25962398e+03\n",
      "  -1.36534121e+03   1.68957203e+03   1.95885521e+02   1.85627179e+02\n",
      "  -7.37976123e+02   2.18031022e+03  -2.60147670e+03  -5.00911411e+02\n",
      "   1.05312636e+02  -1.27231077e+03   9.80165746e+02   5.71080206e+01\n",
      "  -3.46484731e+02  -6.25097363e+02  -6.95969263e+02  -5.45051447e+02\n",
      "  -3.93995915e+02   3.39709847e+02  -1.72374263e+03   2.95911340e+01\n",
      "  -9.76479221e+02   8.63259836e+01   1.25814014e+03  -1.30680135e+03\n",
      "   7.64363417e+01  -1.38081905e+02   6.83436279e+02  -5.09356656e+01\n",
      "   1.02354218e+03   1.98515184e+02   2.04009970e+02  -2.88147906e+02\n",
      "   1.35669293e+03   5.71131503e+02  -7.23396069e+02  -4.88188950e+02\n",
      "   7.79406068e+02   1.10126353e+03  -1.09050982e+02  -2.94938390e+02\n",
      "  -4.38246689e+02  -1.81523650e+03   1.79583747e+03  -1.71125384e+03\n",
      "  -1.76287677e+03  -8.40838450e+02  -1.47193857e+03  -7.58426347e+02\n",
      "   3.99920393e+02  -8.69635964e+02   5.88019463e+02  -4.41025216e+02\n",
      "   2.42733910e+03  -5.38571601e+02  -6.56432773e+02  -1.61134648e+03\n",
      "   7.04630629e+02  -2.45743668e+03  -1.81171051e+02  -5.92673359e+02\n",
      "  -2.82062505e+03  -1.18261941e+03  -2.08006521e+02   3.59589782e+02\n",
      "   1.16838170e+03   4.71892294e+02   1.67810236e+03  -1.82592911e+03]\n",
      "\tSampling user factors: time=28.06\n",
      "\tSampling item factors..."
     ]
    }
   ],
   "source": [
    "#parallel\n",
    "import paral_gibbs3_expomf_cov\n",
    "n_jobs = -1\n",
    "coder = paral_gibbs3_expomf_cov.ExpoMF(n_components=n_components, max_iter=max_iter, batch_size=10000, \n",
    "                          batch_sgd=100, max_epoch=max_epoch, init_std=0.01,\n",
    "                          n_jobs=n_jobs, random_state=98765, save_params=True, save_dir=save_dir, \n",
    "                          early_stopping=True, verbose=True, \n",
    "                          lam_y=1., lam_theta=lam, lam_beta=lam, lam_nu=lam, init_mu=init_mu, learning_rate=.5, debugCov=True)\n",
    "para_dir = 'gowalla_proParal_gibb3_ExpoMF_params_K100_lam1E-05_initmu1E-02_maxepoch10/_iter9.npz'\n",
    "coder.fit(train_data, pi, para_dir, init_only_mu=False, random_mu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#non parallel\n",
    "para_dir = '/home/ec2-user/notebook/expo-mf/src/YELP_20000USERS_100_feature_restaurant_only_location_only_Numeric_Id100_lxam1E-05_initmu1E-02_maxepoch10/ExpoMF_cov_K100_mu1.0e-02_iter12.npz'\n",
    "coder.fit(train_data, pi, para_dir, init_only_mu=False, random_mu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#non parallel\n",
    "para_dir = '/home/ec2-user/notebook/expo-mf/src/YELP_20000USERS_100_feature_restaurant_only_location_only_Numeric_Id100_lxam1E-05_initmu1E-02_maxepoch10/ExpoMF_cov_K100_mu1.0e-02_iter12.npz'\n",
    "coder.fit(train_data, pi, para_dir, init_only_mu=False, random_mu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that after a few epochs the validation loss will not decrease. However, we empirically found that it is still better to train for more epochs, instead of stop the SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance on heldout testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_params = len(glob.glob(os.path.join(save_dir, '*.npz')))\n",
    "\n",
    "# params = np.load(os.path.join(save_dir, 'ExpoMF_cov_K%d_mu%.1e_iter%d.npz' % (n_components, init_mu, 0)))\n",
    "params = np.load(os.path.join(save_dir, '_iter9.npz'))\n",
    "\n",
    "U, V, nu, alpha = params['U'], params['V'], params['nu'], params['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank by $\\mathbb{E}[y_{ui}] = \\mu_{ui}\\theta_u^\\top\\beta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100: 0.0193\n",
      "Test NDCG@100: 0.0177\n",
      "Test NDCG@100: 0.0218\n",
      "Test NDCG@100: 0.0198\n",
      "Test NDCG@100: 0.0232\n",
      "Test NDCG@100: 0.0198\n",
      "Test NDCG@100: 0.0190\n",
      "Test NDCG@100: 0.0196\n",
      "Test NDCG@100: 0.0229\n",
      "Test NDCG@100: 0.0192\n",
      "Test NDCG@100: 0.0215\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    n_params = len(glob.glob(os.path.join(save_dir, '*.npz')))\n",
    "\n",
    "    # params = np.load(os.path.join(save_dir, 'ExpoMF_cov_K%d_mu%.1e_iter%d.npz' % (n_components, init_mu, 0)))\n",
    "    params = np.load(os.path.join(save_dir, '_iter' + str(i)+ '.npz'))\n",
    "\n",
    "    U, V, nu, alpha = params['U'], params['V'], params['nu'], params['alpha']\n",
    "    import rec_eval\n",
    "    mu = {'params': [nu, pi, alpha], 'func': gibbs3_expomf_cov.get_mu}\n",
    "\n",
    "#     print 'Test Recall@20: %.4f' % rec_eval.recall_at_k(train_data, test_data, U, V, k=20, mu=mu, vad_data=vad_data)\n",
    "#     print 'Test Recall@50: %.4f' % rec_eval.recall_at_k(train_data, test_data, U, V, k=50, mu=mu, vad_data=vad_data)\n",
    "    print 'Test NDCG@100: %.4f' % rec_eval.normalized_dcg_at_k(train_data, test_data, U, V, k=100, mu=mu, vad_data=vad_data)\n",
    "#     print 'Test MAP@100: %.4f' % rec_eval.map_at_k(train_data, test_data, U, V, k=100, mu=mu, vad_data=vad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
